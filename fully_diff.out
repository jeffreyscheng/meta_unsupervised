THCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory
Loaded file: fully_diff.bayes
[31mBayesian Optimization[0m
[94m---------------------------------------------------------------------------------------------------------------------------[0m
 Step |   Time |      Value |   learner_batch_size |   learning_rate |   meta_mid |      mid1 |      mid2 |   update_rate | 
17
   64 | 31m21s |    0.97869 |              17.3389 |          0.0002 |     2.4966 |  412.4306 |  738.9220 |        0.0007 | 
262
   65 | 19m58s |    0.97861 |             262.9929 |          0.0008 |     4.6404 |  196.0058 |  366.7898 |        0.0010 | 
4
   66 | 31m17s |    0.89510 |               4.5395 |          0.0000 |     9.3473 |  416.8777 |  723.5224 |        0.0008 | 
17
   67 | 18m52s | [35m   0.98219[0m | [32m             17.4240[0m | [32m         0.0004[0m | [32m    2.0000[0m | [32m 185.9285[0m | [32m 255.3086[0m | [32m       0.0000[0m | 
221
Encountered Error!
_____
_____
   68 | 01m17s |    0.00000 |             221.2968 |          0.0010 |     8.0765 |  383.4234 |  267.4415 |        0.0010 | 
58
Encountered Error!
_____
_____
   69 | 01m17s |    0.00000 |              58.8127 |          0.0009 |     9.3524 |  419.7570 |  169.5688 |        0.0001 | 
4
   70 | 31m09s |    0.97760 |               4.3626 |          0.0005 |     7.5720 |  399.5195 |  670.6666 |        0.0007 | 
1
   71 | 31m06s |    0.95290 |               1.5028 |          0.0005 |     7.9899 |  394.0265 |  618.6587 |        0.0010 | 
5
   72 | 31m23s |    0.98210 |               5.8839 |          0.0002 |     3.5760 |  393.7160 |  636.5442 |        0.0004 | 
3
   73 | 18m34s |    0.95550 |               3.5247 |          0.0008 |     3.3228 |   92.9584 |  298.4475 |        0.0010 | 
295
   74 | 24m05s |    0.64705 |             295.5689 |          0.0000 |     7.6228 |  248.4758 |  234.3013 |        0.0008 | 
285
   75 | 27m10s |    0.30165 |             285.7541 |          0.0000 |     9.5751 |  278.3939 |  225.3391 |        0.0002 | 
264
   76 | 21m00s |    0.97676 |             264.9684 |          0.0005 |     6.8559 |  205.0146 |  360.3756 |        0.0010 | 
255
   77 | 20m23s |    0.97878 |             255.3880 |          0.0008 |     4.7221 |  205.9357 |  368.7863 |        0.0010 | 
71
   78 | 03m17s |    0.46771 |              71.7109 |          0.0000 |    10.0000 |   20.0000 |  368.6416 |        0.0000 | 
1
   79 | 30m22s |    0.95300 |               1.5529 |          0.0005 |     5.9157 |  398.1849 |  633.8227 |        0.0009 | 
40
   80 | 24m08s |    0.74520 |              40.9132 |          0.0008 |     6.8108 |  273.7473 |  128.4550 |        0.0008 | 
32
   81 | 23m46s |    0.73848 |              32.3655 |          0.0000 |     6.3524 |  262.5192 |  150.5021 |        0.0000 | 
19
   82 | 30m38s |    0.92936 |              19.9621 |          0.0009 |     9.3486 |  623.0168 |  752.6314 |        0.0009 | 
16
   83 | 30m35s |    0.97800 |              16.2221 |          0.0006 |     6.0372 |  622.7306 |  762.0046 |        0.0007 | 
214
   84 | 30m33s |    0.79663 |             214.2208 |          0.0010 |    10.0000 |  386.7427 |  290.7169 |        0.0010 | 
349
Encountered Error!
_____
_____
   85 | 00m18s |    0.00000 |             349.4944 |          0.0007 |     5.0543 |  403.0570 |  325.0632 |        0.0001 | 
1
Encountered Error!
_____
_____
   86 | 00m20s |    0.00000 |               1.3975 |          0.0004 |     8.6073 |  621.0524 |  784.6130 |        0.0006 | 
20
   87 | 30m36s |    0.98060 |              20.6097 |          0.0003 |     2.4093 |  634.6774 |  762.0745 |        0.0005 | 
148
   88 | 11m52s |    0.97509 |             148.8935 |          0.0008 |     9.2383 |  106.5947 |  268.6727 |        0.0002 | 
172
   89 | 09m40s |    0.93294 |             172.9062 |          0.0005 |     3.4044 |   91.6226 |  273.7609 |        0.0007 | 
190
   90 | 11m03s |    0.77095 |             190.6728 |          0.0002 |     7.4945 |  100.9441 |  267.2588 |        0.0007 | 
65
   91 | 28m08s |    0.79356 |              65.4393 |          0.0003 |     5.8694 |  276.4779 |  273.8465 |        0.0006 | 
205
   92 | 09m09s |    0.97398 |             205.4225 |          0.0008 |     4.6808 |   89.1587 |  228.0582 |        0.0009 | 
209
   93 | 09m28s |    0.89484 |             209.6198 |          0.0002 |     4.3964 |   92.2801 |  236.8853 |        0.0001 | 
{'max_val': 0.9821928771508603, 'max_params': {'mid1': 185.92848025411553, 'mid2': 255.30859815220873, 'meta_mid': 2.0, 'learning_rate': 0.00042919033808678115, 'update_rate': 1e-06, 'learner_batch_size': 17.424049877949205}}
{'values': [0.7294376625975585, 0, 0, 0.9138655462184874, 0.6918016194331984, 0.9035035035035035, 0.6248983739837398, 0.7482748274827483, 0.1032, 0.9016, 0, 0, 0.0982, 0.9557, 0.8572, 0.9633961883634163, 0.8962, 0.9773508594539939, 0, 0, 0.576969696969697, 0.783922697368421, 0.6445492872917085, 0.8216286514605843, 0.5948517628205128, 0.7876313909582611, 0.9687, 0.596285140562249, 0.4107643057222889, 0.7925403225806451, 0.9692, 0.6948253428085277, 0, 0, 0.6337858220211161, 0.9816981698169817, 0.9075731670521975, 0, 0, 0.9804295463669209, 0.8512280701754386, 0.9752, 0.7949874686716792, 0.6274268104776579, 0, 0, 0.9807980798079808, 0.9748899559823929, 0.6769707883153261, 0.97099558410277, 0.8504401760704282, 0.9588, 0.9787915166066427, 0.9506072874493927, 0.45671191553544493, 0.7713162668816771, 0.9770623742454728, 0.9764905962384954, 0.9801, 0.9777665995975855, 0.9786914765906363, 0.9786058658095621, 0.8951, 0.9821928771508603, 0, 0, 0.9776, 0.9529, 0.9821, 0.9554955495549555, 0.6470467385721623, 0.30165413533834584, 0.9767608517608518, 0.9787833081950729, 0.4677062374245473, 0.953, 0.7452, 0.7384815705128205, 0.9293576145687412, 0.978, 0.7966273872409589, 0, 0, 0.9806, 0.9750907624041952, 0.9329390537289495, 0.7709514170040486, 0.7935646053293112, 0.9739837398373984, 0.8948386439987783], 'params': [{'mid1': 443.24309613798164, 'mid2': 800.0, 'meta_mid': 2.0, 'learning_rate': 1e-06, 'update_rate': 0.0003813056541988691, 'learner_batch_size': 38.583854283464106}, {'mid1': 424.57988049875496, 'mid2': 522.0719834583616, 'meta_mid': 2.0, 'learning_rate': 0.001, 'update_rate': 1e-06, 'learner_batch_size': 470.6764363367915}, {'mid1': 21.56595915728484, 'mid2': 612.8849398257205, 'meta_mid': 2.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 1.0}, {'mid1': 271.84786064145237, 'mid2': 347.332106511117, 'meta_mid': 4.095946181018901, 'learning_rate': 0.00041057764731830987, 'update_rate': 0.00015476087131438202, 'learner_batch_size': 98.76511137927655}, {'mid1': 264.8029315682286, 'mid2': 231.36890531197744, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 247.36763640209583}, {'mid1': 167.29741258902192, 'mid2': 223.92848011747648, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 1e-06, 'learner_batch_size': 15.158088309945178}, {'mid1': 114.66084602665603, 'mid2': 332.2604696959557, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 164.0662662882323}, {'mid1': 250.8111614118332, 'mid2': 220.90176976444317, 'meta_mid': 2.0, 'learning_rate': 0.0001912744146389135, 'update_rate': 1e-06, 'learner_batch_size': 99.89135923932592}, {'mid1': 613.5504988830145, 'mid2': 99.20827611832196, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 1e-06, 'learner_batch_size': 1.0}, {'mid1': 664.3481555533276, 'mid2': 800.0, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 0.00027353463790548465, 'learner_batch_size': 1.0}, {'mid1': 649.0196727491337, 'mid2': 800.0, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 0.001, 'learner_batch_size': 182.0645151193192}, {'mid1': 597.6546802176549, 'mid2': 657.8125588500984, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 1.0}, {'mid1': 800.0, 'mid2': 800.0, 'meta_mid': 2.0, 'learning_rate': 0.001, 'update_rate': 1e-06, 'learner_batch_size': 1.0}, {'mid1': 168.19230486705092, 'mid2': 328.25735821881295, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 1.0}, {'mid1': 563.3507325253364, 'mid2': 800.0, 'meta_mid': 10.0, 'learning_rate': 0.0007060810643290838, 'update_rate': 0.0007060810643290838, 'learner_batch_size': 1.0}, {'mid1': 260.6041336847559, 'mid2': 359.41097835089874, 'meta_mid': 10.0, 'learning_rate': 0.0006084321067004682, 'update_rate': 0.0003984587880018163, 'learner_batch_size': 211.73729983396274}, {'mid1': 234.87282825029678, 'mid2': 273.9037292043367, 'meta_mid': 10.0, 'learning_rate': 0.000999999185392424, 'update_rate': 0.000999999185392424, 'learner_batch_size': 1.0}, {'mid1': 386.4345782239878, 'mid2': 283.2859796293723, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 215.41259823376276}, {'mid1': 502.2444311960289, 'mid2': 174.1796844312048, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 305.1565756103842}, {'mid1': 311.0778993195164, 'mid2': 304.7897339848457, 'meta_mid': 10.0, 'learning_rate': 0.000494007894836248, 'update_rate': 0.00042197599291251143, 'learner_batch_size': 175.04858146350534}, {'mid1': 205.10802359158347, 'mid2': 412.5138835029107, 'meta_mid': 2.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 132.9618014239262}, {'mid1': 384.4156612263044, 'mid2': 320.2250332744378, 'meta_mid': 6.989479577204893, 'learning_rate': 0.0006114217361985393, 'update_rate': 1e-06, 'learner_batch_size': 304.4537548310301}, {'mid1': 216.20596573580173, 'mid2': 362.640097399709, 'meta_mid': 9.203991891660426, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 293.74634385547125}, {'mid1': 467.61206377796105, 'mid2': 293.29282751928434, 'meta_mid': 4.08116901292414, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 204.81997381811945}, {'mid1': 188.82621808180429, 'mid2': 300.54470616360123, 'meta_mid': 2.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 78.93919185159339}, {'mid1': 400.7912734624708, 'mid2': 224.6812171080234, 'meta_mid': 2.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 239.84043460171088}, {'mid1': 265.07862198888034, 'mid2': 143.1863227934191, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 5.749708294792041}, {'mid1': 211.70371004771923, 'mid2': 107.73830998168039, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 83.25274541075221}, {'mid1': 201.39571342596687, 'mid2': 341.1895333837206, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 204.49492786492857}, {'mid1': 301.96992269208613, 'mid2': 426.6280134202306, 'meta_mid': 10.0, 'learning_rate': 0.0004971666853729453, 'update_rate': 1e-06, 'learner_batch_size': 248.91021432715186}, {'mid1': 55.440771326159975, 'mid2': 309.4424405306808, 'meta_mid': 10.0, 'learning_rate': 0.0002746797972252711, 'update_rate': 0.001, 'learner_batch_size': 1.0}, {'mid1': 20.0, 'mid2': 325.6367108530642, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 1e-06, 'learner_batch_size': 103.14478221219625}, {'mid1': 406.96518154148583, 'mid2': 288.57231922720115, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.0003919377371983573, 'learner_batch_size': 234.2655380718714}, {'mid1': 567.0121259989555, 'mid2': 788.4303812248987, 'meta_mid': 9.683136512538699, 'learning_rate': 0.0006665044217558333, 'update_rate': 0.0005242452713185191, 'learner_batch_size': 24.386786259668998}, {'mid1': 379.1567199468693, 'mid2': 259.4216989869126, 'meta_mid': 6.70020014359512, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 195.05074927785725}, {'mid1': 167.50370604792167, 'mid2': 265.35460321201515, 'meta_mid': 3.59174053570064, 'learning_rate': 0.0002584175189510857, 'update_rate': 0.00026841307783824757, 'learner_batch_size': 9.464539369020953}, {'mid1': 24.704124071563527, 'mid2': 353.16475646181317, 'meta_mid': 9.999999725947934, 'learning_rate': 6.442444700014975e-05, 'update_rate': 1e-06, 'learner_batch_size': 61.0691574669905}, {'mid1': 366.23248643884193, 'mid2': 289.3340780538988, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 217.7276550530166}, {'mid1': 38.83021100073741, 'mid2': 336.3389484754378, 'meta_mid': 4.060404423300471, 'learning_rate': 0.0003819423349319163, 'update_rate': 0.00017073208403481745, 'learner_batch_size': 53.979914672338495}, {'mid1': 246.23106372530853, 'mid2': 146.42447917724752, 'meta_mid': 6.020968196157715, 'learning_rate': 0.0006669522749695926, 'update_rate': 0.00020694005810751248, 'learner_batch_size': 47.28394913558323}, {'mid1': 255.10752494963415, 'mid2': 135.4235703833699, 'meta_mid': 7.792175235413391, 'learning_rate': 0.00020100191116604726, 'update_rate': 0.0009547532313830517, 'learner_batch_size': 57.47050408466975}, {'mid1': 109.30295324357714, 'mid2': 287.66726309775026, 'meta_mid': 3.551098236495295, 'learning_rate': 0.0008079289051560564, 'update_rate': 0.0009124320581326903, 'learner_batch_size': 5.669467559404341}, {'mid1': 276.686699875463, 'mid2': 420.56156993516606, 'meta_mid': 3.986520726284967, 'learning_rate': 0.0007228344921922505, 'update_rate': 0.0005704134316148956, 'learner_batch_size': 285.1529633047967}, {'mid1': 276.8095300939114, 'mid2': 417.59669609406143, 'meta_mid': 5.282703029166281, 'learning_rate': 0.0001743657971061378, 'update_rate': 0.0007436722416406307, 'learner_batch_size': 295.7977380009743}, {'mid1': 398.9124991107144, 'mid2': 278.45126630069905, 'meta_mid': 10.0, 'learning_rate': 0.0009111255447613496, 'update_rate': 0.001, 'learner_batch_size': 201.04482982810094}, {'mid1': 138.63085639773476, 'mid2': 268.8048346464573, 'meta_mid': 9.059603071443192, 'learning_rate': 0.0003961478515516684, 'update_rate': 0.0003085537257084586, 'learner_batch_size': 2.639773883894714}, {'mid1': 202.29070348511883, 'mid2': 307.1380799536595, 'meta_mid': 6.5036350143794275, 'learning_rate': 0.0002861984232516745, 'update_rate': 7.329953328787097e-05, 'learner_batch_size': 9.567890135433851}, {'mid1': 197.74660266985777, 'mid2': 293.94404154767375, 'meta_mid': 4.388026679649241, 'learning_rate': 0.00018876130693265436, 'update_rate': 0.0005168078982540038, 'learner_batch_size': 7.919607483388002}, {'mid1': 264.6151841032429, 'mid2': 117.58530903899069, 'meta_mid': 6.289862412376347, 'learning_rate': 0.00013572105808729176, 'update_rate': 0.0005310431299062066, 'learner_batch_size': 51.693217787187066}, {'mid1': 269.8629452826242, 'mid2': 122.91519006061696, 'meta_mid': 6.405074901948096, 'learning_rate': 0.0004325405991605047, 'update_rate': 0.0006148530710349547, 'learner_batch_size': 47.05137179419253}, {'mid1': 648.4116613981985, 'mid2': 791.6803550399567, 'meta_mid': 8.872567590487751, 'learning_rate': 1.3647757302662352e-05, 'update_rate': 0.0001928933524525156, 'learner_batch_size': 6.681354398651587}, {'mid1': 174.38459048558363, 'mid2': 301.59088657047926, 'meta_mid': 5.406600752684507, 'learning_rate': 2.852584483752455e-05, 'update_rate': 0.0008806670211379646, 'learner_batch_size': 8.726686909353507}, {'mid1': 272.7696592520572, 'mid2': 138.76415321290645, 'meta_mid': 7.043200814441448, 'learning_rate': 0.001, 'update_rate': 0.0007122012598390407, 'learner_batch_size': 34.97539499171274}, {'mid1': 213.91389536421298, 'mid2': 357.44587835620433, 'meta_mid': 7.969385457642742, 'learning_rate': 0.00026080982894195547, 'update_rate': 0.0009112139409398847, 'learner_batch_size': 260.3907375708412}, {'mid1': 224.17536107973726, 'mid2': 353.8226522289515, 'meta_mid': 9.37997061864246, 'learning_rate': 1.0001279233633167e-06, 'update_rate': 1.0001279233633167e-06, 'learner_batch_size': 255.85482849916556}, {'mid1': 292.7199672959575, 'mid2': 372.9304781837489, 'meta_mid': 4.045958599243202, 'learning_rate': 0.00025425251778660353, 'update_rate': 0.0009867795782013628, 'learner_batch_size': 82.30127874892281}, {'mid1': 287.89584263890083, 'mid2': 392.11986494444557, 'meta_mid': 6.427397301838496, 'learning_rate': 0.0004609895004342043, 'update_rate': 0.0008755207549531057, 'learner_batch_size': 70.27427024640112}, {'mid1': 437.9861539780326, 'mid2': 781.357141288967, 'meta_mid': 8.43079032897881, 'learning_rate': 0.000854282129746436, 'update_rate': 0.0009840156658113466, 'learner_batch_size': 7.2486339895151914}, {'mid1': 439.32879538760636, 'mid2': 761.9218234227814, 'meta_mid': 9.48083090759402, 'learning_rate': 0.0004709806910664998, 'update_rate': 0.0004615396372217176, 'learner_batch_size': 5.861932394494209}, {'mid1': 277.16685715989394, 'mid2': 392.7142893380414, 'meta_mid': 6.98670807610001, 'learning_rate': 0.00044985395886118935, 'update_rate': 0.001, 'learner_batch_size': 70.35303463068944}, {'mid1': 412.43055940752174, 'mid2': 738.9220025336465, 'meta_mid': 2.4965778556287486, 'learning_rate': 0.0002062899716611844, 'update_rate': 0.000660429528723174, 'learner_batch_size': 17.338929746712758}, {'mid1': 196.00575519072896, 'mid2': 366.78983187489195, 'meta_mid': 4.640440648796954, 'learning_rate': 0.0007900278678889599, 'update_rate': 0.001, 'learner_batch_size': 262.99287016379407}, {'mid1': 416.8776771161661, 'mid2': 723.522440784468, 'meta_mid': 9.34734463332624, 'learning_rate': 1.1707629637149247e-05, 'update_rate': 0.000843863868380147, 'learner_batch_size': 4.539491899530367}, {'mid1': 185.92848025411553, 'mid2': 255.30859815220873, 'meta_mid': 2.0, 'learning_rate': 0.00042919033808678115, 'update_rate': 1e-06, 'learner_batch_size': 17.424049877949205}, {'mid1': 383.4234257241085, 'mid2': 267.44147641892323, 'meta_mid': 8.076509006372005, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 221.2967594110657}, {'mid1': 419.7570159188152, 'mid2': 169.5687898742091, 'meta_mid': 9.352377088616537, 'learning_rate': 0.0009191280889409902, 'update_rate': 8.187191105900988e-05, 'learner_batch_size': 58.81272676088525}, {'mid1': 399.51947140438745, 'mid2': 670.6666482837958, 'meta_mid': 7.5719779689818765, 'learning_rate': 0.00045604748870653266, 'update_rate': 0.000725359834226102, 'learner_batch_size': 4.36262408467445}, {'mid1': 394.02650772893685, 'mid2': 618.6586712102669, 'meta_mid': 7.989883749715897, 'learning_rate': 0.00046746222174195783, 'update_rate': 0.0009779428805627526, 'learner_batch_size': 1.502828635142782}, {'mid1': 393.715986928873, 'mid2': 636.5442234925612, 'meta_mid': 3.5760008268393157, 'learning_rate': 0.00020364662029085685, 'update_rate': 0.00042271219076197675, 'learner_batch_size': 5.883859925240416}, {'mid1': 92.95839893940624, 'mid2': 298.4475299419959, 'meta_mid': 3.322792057302066, 'learning_rate': 0.0008179672174389156, 'update_rate': 0.001, 'learner_batch_size': 3.5246890641505644}, {'mid1': 248.4758264439947, 'mid2': 234.3012565257936, 'meta_mid': 7.622844099503145, 'learning_rate': 1.7974157549086015e-05, 'update_rate': 0.0007500868766113965, 'learner_batch_size': 295.5688713632339}, {'mid1': 278.3938733157006, 'mid2': 225.33913197067167, 'meta_mid': 9.57512816700463, 'learning_rate': 1.0000000000000175e-06, 'update_rate': 0.0001902590484185132, 'learner_batch_size': 285.7541065744088}, {'mid1': 205.01455095743353, 'mid2': 360.3756391816061, 'meta_mid': 6.855885663181677, 'learning_rate': 0.0004983347489193497, 'update_rate': 0.001, 'learner_batch_size': 264.9684232324908}, {'mid1': 205.93573198826425, 'mid2': 368.78631557533834, 'meta_mid': 4.722084545602678, 'learning_rate': 0.0007672627654418491, 'update_rate': 0.001, 'learner_batch_size': 255.38798126003368}, {'mid1': 20.0, 'mid2': 368.64156666303387, 'meta_mid': 10.0, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 71.7109400623314}, {'mid1': 398.18488263490946, 'mid2': 633.8226798181505, 'meta_mid': 5.915655527543739, 'learning_rate': 0.0005438542912155251, 'update_rate': 0.0009142396292012896, 'learner_batch_size': 1.5529380493299696}, {'mid1': 273.7472990806391, 'mid2': 128.45501073447053, 'meta_mid': 6.810836643067864, 'learning_rate': 0.000815173658674164, 'update_rate': 0.0008188204554618922, 'learner_batch_size': 40.913167065882476}, {'mid1': 262.51924768247943, 'mid2': 150.50211015861993, 'meta_mid': 6.3523931585064926, 'learning_rate': 1e-06, 'update_rate': 1e-06, 'learner_batch_size': 32.36554325074285}, {'mid1': 623.0167603609243, 'mid2': 752.6314031325867, 'meta_mid': 9.348616733278417, 'learning_rate': 0.000867234013894805, 'update_rate': 0.0009159191610710812, 'learner_batch_size': 19.962071605967786}, {'mid1': 622.7306255454173, 'mid2': 762.0046266573028, 'meta_mid': 6.037212505111111, 'learning_rate': 0.0005844808169137748, 'update_rate': 0.0006896422492814059, 'learner_batch_size': 16.222140641293016}, {'mid1': 386.7427087144401, 'mid2': 290.7169234737568, 'meta_mid': 10.0, 'learning_rate': 0.001, 'update_rate': 0.001, 'learner_batch_size': 214.22084722951053}, {'mid1': 403.0570321394112, 'mid2': 325.0632120304281, 'meta_mid': 5.054294692279678, 'learning_rate': 0.000715718370656881, 'update_rate': 7.600985776218907e-05, 'learner_batch_size': 349.49441194317524}, {'mid1': 621.0524304923589, 'mid2': 784.6130457478336, 'meta_mid': 8.607287261120224, 'learning_rate': 0.0004212717549013754, 'update_rate': 0.0006075744121927493, 'learner_batch_size': 1.3974786631122988}, {'mid1': 634.6773723340328, 'mid2': 762.0744846698753, 'meta_mid': 2.409259097506794, 'learning_rate': 0.0003413482038900354, 'update_rate': 0.00047017796914263676, 'learner_batch_size': 20.60969173078494}, {'mid1': 106.5947186889531, 'mid2': 268.6726924373685, 'meta_mid': 9.238306083695043, 'learning_rate': 0.000760302394255017, 'update_rate': 0.00024257895839593626, 'learner_batch_size': 148.89348364810846}, {'mid1': 91.62262809252209, 'mid2': 273.7609007239805, 'meta_mid': 3.40441856626991, 'learning_rate': 0.0004804537106582712, 'update_rate': 0.0007228135351376412, 'learner_batch_size': 172.90618500414547}, {'mid1': 100.94411032302612, 'mid2': 267.25882993589096, 'meta_mid': 7.494502039213642, 'learning_rate': 0.00021585126974946062, 'update_rate': 0.000725641634952269, 'learner_batch_size': 190.672837980224}, {'mid1': 276.4778856053755, 'mid2': 273.84649868716735, 'meta_mid': 5.8694311236588685, 'learning_rate': 0.0003002574245517596, 'update_rate': 0.0005611766281169155, 'learner_batch_size': 65.43928287323908}, {'mid1': 89.15868412217027, 'mid2': 228.05823361013694, 'meta_mid': 4.6807562112513175, 'learning_rate': 0.0008321915343154298, 'update_rate': 0.0008613688784400395, 'learner_batch_size': 205.42249539729508}, {'mid1': 92.28010638233769, 'mid2': 236.88530281242492, 'meta_mid': 4.3964445573087225, 'learning_rate': 0.0002414118243581706, 'update_rate': 6.081705334658517e-05, 'learner_batch_size': 209.61979980102174}]}Traceback (most recent call last):
  File "/home/jeffch/meta_unsupervised/meta_framework.py", line 125, in bounced
    result = method(*args, **kw)
  File "fully_diff.py", line 147, in train_model
    learner_loss.backward()
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 167, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    variables, grad_variables, retain_graph)
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58
Traceback (most recent call last):
  File "/home/jeffch/meta_unsupervised/meta_framework.py", line 125, in bounced
    result = method(*args, **kw)
  File "fully_diff.py", line 147, in train_model
    learner_loss.backward()
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 167, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    variables, grad_variables, retain_graph)
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCTensorMath.cu:35
Traceback (most recent call last):
  File "/home/jeffch/meta_unsupervised/meta_framework.py", line 125, in bounced
    result = method(*args, **kw)
  File "fully_diff.py", line 144, in train_model
    outputs = learner.forward(images, batch_num)
  File "fully_diff.py", line 60, in forward
    shift = self.get_update(meta_inputs) * self.rate / batch_num
  File "fully_diff.py", line 28, in get_update
    return torch.squeeze(self.conv2(self.conv1(meta_input_stack)), 1)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 357, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 282, in forward
    self.padding, self.dilation, self.groups)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 90, in conv2d
    return f(input, weight, bias)
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58
Traceback (most recent call last):
  File "/home/jeffch/meta_unsupervised/meta_framework.py", line 125, in bounced
    result = method(*args, **kw)
  File "fully_diff.py", line 144, in train_model
    outputs = learner.forward(images, batch_num)
  File "fully_diff.py", line 40, in forward
    old_vj = self.layers[layer_num](out)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 357, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 55, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jeffch/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 835, in linear
    return torch.addmm(bias, input, weight.t())
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/THCTensorCopy.cu:204

